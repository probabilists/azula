{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "This tutorial demonstrates how to build a simple diffusion model with Azula, and train it to generate MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "from tqdm import tqdm\n",
    "\n",
    "from azula.denoise import PreconditionedDenoiser\n",
    "from azula.nn.embedding import SineEncoding\n",
    "from azula.nn.unet import UNet\n",
    "from azula.noise import VPSchedule\n",
    "from azula.sample import DDIMSampler\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiirEFjcXJQQx7i5wvzAZOcd66bTfhn4s1OSJLbSS/mjK4uYhkYz3b0rqNI+Bfiia8ZdV0qeC32Eho7uAndkcfePbNWpvgpMviux06KG8azlhLTyG4h3q4D8Djp8q9j1NXPiB8JvCXhPw/NeWepaq90hKqk7oyk7GYdIx3A714nRRX0V8MPihoWk+ELPT9RuGSe3jlZ8tGoOZWYAZYHODXr8PiDTZ9Bj1lLmP7E8aPv8xfl3YwCc4B+Yd68s0n4+6HcamIboagkTgKrSRQqqkkDJO/p1rxTxR4rvrrxbrM9reBraS+neEhEIKGRivOOeMVzc95cXIxNJuGc9AP5VBRRQCR0NfQ3wg8W2Wt6BD4S1RoC8kpSOIQsSyRxKwJJyufkP5V5J4g8Aa9oU1w01gyW0IyXaeNjjbuPQ/XtXKUUUUUVLbXMtpcLPA+yRc4bAOMjHevorwJ8YLPXha6Fr0l1Pc3oNszGOKNHaR9qjKsD0bHAzXLfFf4W3GlS32uadbxCwUByiPI75eUjuCOjL3rxmiiilALMAOpOBXf+DvhZrHiUwzyWUwsnYgyRXESnGzcOCSe47V9A6H8KvC/h5re8W18ye1bzVknjiZlKtuByEzkY7Vxfxk8f6RPoOo6HY6o321ljXyljlX5lmBbnAHRT37V85UUV3fhf4T+IvFNnHe2gt47dzgNP5i/whgchCMcivfNH+Gfg7w3NBdXFtawXELAq5vZRhg25eGbHap/FPxV8M+HLWWGLUI7meJVwtnLFKR820rgv1GDkV84+KPiPr/iYyxXOoPJauQdjQRKfu7Tyo9z3rj6KKK2LPxZ4k063W3sfEGq20C9I4L2RFHGOgOOgA/Ci48W+JLsYufEGqzDOf3l7I3P4msqSWSaRpJXaSRiSzMckk9yaZRRRX//2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAAB8ElEQVR4Ae2WPWhTURTHf9HgoFhDFgOClHZIQZQ6qCCCFJEi1CHYxUIXdbPFqUu3DoqgDm1xyFToUFzVqQW1dSgEgq2L4m7tVqNSYqVpe+57Xu8j9+UNnkSo5A65Xy/n/7vnnPsB7dL2wH/hgVTCKg7CsXB6hMPkuQuPuclPeMiE/d8B2/jbWm0g7SufhENc5BIZuOGmPzMFBX7wHpbcsJrAc+JZXv3xndNhh1tsmv4XvsInN9N8giwl6HIKJSrQxy8bUTcTttQEagNeGDcYgwFWTNBglavGd6e4V49u+2oCL4yB5Q7JlyK3YZg5K9WgVhN4PgiEvsvvN9O6wzPJoaSiJoj3gZE8wku4zDUWkgBQE6gNNF4CdMM72QlvoMxTduNX0lICkSwww1EjPc4s63EMrSaA0zyBK6Jd5D6seRBqArWBpDD+xs3AdfFlitfI6VBf/gVBoLlFmm3oZ7EOQU0Qfx5EVM4wCOdEHz7A28hM2GwpQR5GJZlzoVTNpLJ/OqkJ1AYaJVKOIfOk6bROK8tOeGE70boVBMfNVTZNj9WR2/oRz2P8F3zQbIKsbPveyPtgWU6DeahaGr9WE6gNuDBeMA+D85ywlFUm4UH4srJjMbWawO3GgqR9UD4it2JNnsWVGEFvSE3gWWwP7EcP7AGgz0wcFy1bPgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform(rows):\n",
    "    rows[\"image\"] = list(map(to_tensor, rows[\"image\"]))\n",
    "    rows[\"label\"] = list(map(torch.as_tensor, rows[\"label\"]))\n",
    "    return rows\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"mnist\", split=\"train\", keep_in_memory=True)\n",
    "dataset = dataset.with_transform(transform)\n",
    "\n",
    "to_pil_image(dataset[0][\"image\"]).resize((64, 64), Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    return 2 * x - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x):\n",
    "    return torch.clip((x + 1) / 2, min=0, max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetWrapper(nn.Module):\n",
    "    def __init__(self, channels: int = 1, emb_features: int = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = UNet(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            hid_channels=[16, 32, 64],\n",
    "            hid_blocks=[2, 2, 2],\n",
    "            attention_heads={2: 1},\n",
    "            mod_features=emb_features,\n",
    "        )\n",
    "\n",
    "        self.label_embedding = nn.Embedding(10, emb_features)\n",
    "        self.time_encoding = nn.Sequential(\n",
    "            SineEncoding(emb_features, omega=1e3),\n",
    "            nn.Linear(emb_features, emb_features),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(emb_features, emb_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x_t, log_snr_t, label):\n",
    "        emb = self.time_encoding(log_snr_t) + self.label_embedding(label)\n",
    "        x_0 = self.unet(x_t, emb)\n",
    "        return x_0\n",
    "\n",
    "\n",
    "denoiser = PreconditionedDenoiser(backbone=UNetWrapper(), schedule=VPSchedule()).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(denoiser.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [18:35<00:00, 17.42s/it, loss=0.151]\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "for _ in (bar := tqdm(range(64))):\n",
    "    losses = []\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"image\"].to(device=device)\n",
    "        label = batch[\"label\"].to(device=device)\n",
    "\n",
    "        x = preprocess(x)\n",
    "        t = torch.rand(len(x), device=device)\n",
    "\n",
    "        loss = denoiser.loss(x, t, label=label)\n",
    "        loss.backward()\n",
    "        losses.append(loss.detach())\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    bar.set_postfix(loss=torch.stack(losses).mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABAAEABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiuo0X4e+Jtdt0uLTTLkQP92R7eTawwCCCFIwQRg16h4b+BE6LbvrkFnMCcSKk0yn730HavRbT4OeBbZUZtDHmAckXk/XHP8dTS/CDwFOxZ9CyT1/0uf8A+Lrh/EXwX0bT7C+vLewgVFkzEBczFlQuAByeuDXzpRRX0x4J+Lng3SvCWlWF/qsdtPb2sUUiJaTH5ljUHJCkE5B5qnr3x7toFH9i3FlcnzAD5ttOPlwcnqO+KypPj9evZPxpon4wBbze3+19araJ8e9TN+x1M2EcBTqsMx5yO249s17dY3tn4x8KxTwyl4riKNnMalMNhXwNw9xXxZf232O9kt+fkx1OTyAf61Woooop8MTTzxwoMvIwVR7k4r7A+G+lJ4Z+H1l54SMTRRXD4Y9WjQc7sYOR0r5R8S31vqXiC6u7UMIZNm0NjPCAHoT3FZVFFFFdp8LPDp8SeOLSDyjJHbFLqUBlGEWRASd3UfN0619B/E7xLbeFfBVzZ2ska3kcMPkQvGxBXzFXquAOAe46V8kUUUUUV9YfCHSYtJ8A6fdTKqzCOcSSBjjHnMe/HQCvn/4na1NrXjvU3lm8xLeeW3iO1RhFlfAGOvXr1rj6KKKKK+ibz4t+GtK8BnT9Cv4Jr0JKghktZgAG3nrtUdSO/evn2+u5L+/uLyUKJJ5WlYL0BYknGe3NQUV//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAAAAACPAi4CAAACGklEQVR4Ae2XsU8UQRSHv91DEkQIRgIkFCYaQkElFJpcwYVoQWhsKEiorOy08Y/QDgjGlpoKEhoKCkqlgmAlhcQCCmJCJBTALe/terszsMcdeXuhYYq9N3Mz733ze/PmbuGuW2ADCAhtDrA7sALcr79X4AYFgqxEHDN3gbkWslC+/5CAR/CcB+zBOSec6YSAyJ9nL6YcgikYp8KQEiiIxIyoMkcfbLBUNIFZxLaUqMQkjFJmDJFsIGE/j4WTR8RHLuB3Or1mFEiwwhtNU6iidYmBCCe5a9NEaZhAx57UAqefhRGUqCROZaMa+4x2RTkQ8x+MxETSb08mOU8zge41aau80s1vswWLPKaTQaS3LyowK1n5oJr85TU7tRXxp5nA7CDbggd2rRNKLbzX0beseV+aCZp1UK0uL19oGx72AOIz5o/cspcVk7/w+tUzoxMCev15doJmNbgSN+s2m8YXbMr9Kudygj/ZarHMBPVFDPUGSttLKUSh/XElfgsJIi9+D9PCIkSHKVLNMGvgZkFsuXTy2ju+itzH8EwfXjMTmB24W/DQvM6R/k7yCea9Ye2YCeodJCfSAjyUFO7yzRlMTTNBQw1K/IJ+OcbjfE/DOoaZwOygoYgVuhX4iJ8Ot2O2nqCLDo23nl8mBbx0NdSgnBzWE/nflNOilh/lkKecwhc+54SXoQI0MKdRXgfqXGMx8/9v8yfFdWQmuAR+N1WQSuZ/WAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=64x64>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = DDIMSampler(denoiser, steps=64).to(device)\n",
    "\n",
    "label = torch.tensor(7, device=device)\n",
    "\n",
    "x1 = sampler.init((1, 1, 28, 28))\n",
    "x0 = sampler(x1, label=label)\n",
    "\n",
    "to_pil_image(postprocess(x0).squeeze()).resize((64, 64), Image.NEAREST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azula",
   "language": "python",
   "name": "azula"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
